{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn import model_selection\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "def log_loss(pred, y):\n",
    "    return -np.sum(y*np.log(pred)+(1-y)*np.log(1-pred))/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaboost(X, y, N):\n",
    "\n",
    "    # Размер выборки\n",
    "    n_objects = len(X)\n",
    "\n",
    "    # Запишем количество классов в переменную\n",
    "    n_classes = len(np.unique((y)))\n",
    "\n",
    "    # Начальные веса деревьев\n",
    "    w = np.ones(n_objects) / n_objects\n",
    "\n",
    "    # Деревья с весами будем записывать в список\n",
    "    models = []\n",
    "\n",
    "    for n in range(N):\n",
    "        # Зададим дерево и обучим его\n",
    "        clf = LogisticRegression()\n",
    "      \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            #и здесь обучаем модели\n",
    "            clf.fit(X, y, w)\n",
    "    \n",
    "            predictions = clf.predict_proba(X)[:, 1]\n",
    "            e = log_loss(predictions, y)\n",
    "            # отбросим дерево, если его ошибка больше 0.5\n",
    "            # Запишем условие в общем виде (применимо к небинарным классификаторам)\n",
    "            if e >= 1 - 1/n_classes: \n",
    "                break\n",
    "    \n",
    "            # Вычислим вес для дерева\n",
    "            alpha = 0.5 * np.log((1 - e) / e)\n",
    "    \n",
    "            # Найдем индексы правильно классифицированных элементов\n",
    "            match = (predictions > 0.5).astype(int) == y\n",
    "    \n",
    "            # Увеличим веса для неправильно классифицированных элементов\n",
    "            w[~match] *= np.exp(alpha)\n",
    "    \n",
    "            # Нормализуем веса\n",
    "            w /= w.sum()\n",
    "    \n",
    "            # Добавим дерево с весом в список\n",
    "            models.append((alpha, clf))\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.7547914838032729, LogisticRegression()),\n",
      " (0.7323830658872629, LogisticRegression()),\n",
      " (0.634677859392356, LogisticRegression()),\n",
      " (0.5220876144648005, LogisticRegression()),\n",
      " (0.3796841567991661, LogisticRegression()),\n",
      " (0.2847057034473693, LogisticRegression()),\n",
      " (0.20627649122677189, LogisticRegression()),\n",
      " (0.16144283315795765, LogisticRegression()),\n",
      " (0.11865470261491114, LogisticRegression()),\n",
      " (0.061980655739168285, LogisticRegression()),\n",
      " (0.0661387643080885, LogisticRegression()),\n",
      " (0.05235081837254667, LogisticRegression()),\n",
      " (0.03347187891279153, LogisticRegression()),\n",
      " (0.022075199336590277, LogisticRegression()),\n",
      " (0.03126631934341958, LogisticRegression()),\n",
      " (0.0003172183415144946, LogisticRegression()),\n",
      " (0.013691964620029537, LogisticRegression())]\n"
     ]
    }
   ],
   "source": [
    "N = 50\n",
    "models = adaboost(X_train, y_train, N)\n",
    "pprint(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(X):\n",
    "    return 1/(np.exp(-X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность алгоритма на обучающей выборке: nan\n"
     ]
    }
   ],
   "source": [
    "def predict(X, models):\n",
    "    \n",
    "    n_classes = 2\n",
    "    n_objects = len(X)\n",
    "    \n",
    "    # вначале обозначим предсказание нулевым массивом\n",
    "    y_pred = np.zeros((n_objects, n_classes))\n",
    "    \n",
    "    for alpha, clf in models:\n",
    "        prediction = clf.predict(X)\n",
    "        \n",
    "        # Для каждого предсказания будем прибавлять alpha к\n",
    "        # элементу с индексом предсказанного класса\n",
    "        y_pred[range(n_objects), prediction] += alpha\n",
    "    \n",
    "    # выберем индексы с максимальными суммарными весами -\n",
    "    # получим предсказанные алгоритмом классы\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    return y_pred\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    print(f'Точность алгоритма на обучающей выборке: {(1 - log_loss(predict(X_train, models), y_train)) * 100:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X_train, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность алгоритма на тестовой выборке: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-579fb2ea421e>:4: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.sum(y*np.log(pred)+(1-y)*np.log(1-pred))/len(y)\n",
      "<ipython-input-2-579fb2ea421e>:4: RuntimeWarning: invalid value encountered in multiply\n",
      "  return -np.sum(y*np.log(pred)+(1-y)*np.log(1-pred))/len(y)\n"
     ]
    }
   ],
   "source": [
    "print(f'Точность алгоритма на тестовой выборке: {(1 - log_loss(predict(X_test, models), y_test)) * 100:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    #и здесь обучаем модели\n",
    "\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    \n",
    "    for n in range(1, 31):\n",
    "        mods = adaboost(X_train, y_train, n)\n",
    "        train_errors.append(log_loss(predict(X_train, mods), y_train))\n",
    "        test_errors.append(log_loss(predict(X_test, mods), y_test))\n",
    "    x = list(range(1, 31))\n",
    "    \n",
    "    plt.xlim(0, 30)\n",
    "    plt.plot(x, train_errors, label='train errors')\n",
    "    plt.plot(x, test_errors, label='test errors')\n",
    "    plt.xlabel('N')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Домашнее задание:</b> Реализовать адаптивный бустинг использующий Логистическую Регрессию и меру ошибок LogLoss. Сравнить с точностью адаптивного бустинга на деревьях решений. Для сбора предсказаний можно использовать ту же функцию predict что и для бустинга на деревьях<br>\n",
    "<i>Примечания: в LogLoss необходимо передавать не предсказания полученные с помощью clf.predict(...), а вероятность, полученную с помощью clf.predict_proba(...)[:, 1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Рекоммендуемая реализация LogLoss\n",
    "def log_loss(pred, y): return -np.sum(y*np.log(pred)+(1-y)*np.log(1-pred))/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Для подавления предупреждений о недостаточной сходимости можно использовать:\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    #и здесь обучаем модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Домашнее задание(необязательное, повышенной сложности):</b> Реализовать специальную функцию predict для бустинга на логистической регрессии выводящую предсказания по формуле: $ Predictions=sign(Score_{bust}) $,\n",
    "где sign равен единице для положительных и нулю для отрицательных значений, а $ Score_{bust}= \\sum \\alpha_iScore_i$. Баллы выдаваемые каждой моделью $Score_i$ можно найти при помощи вызова метода decision_function на моделе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
