{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашняя работа №6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Задание:</b> Реализовать адаптивный бустинг использующий Логистическую Регрессию и меру ошибок LogLoss. Сравнить с точностью адаптивного бустинга на деревьях решений. Для сбора предсказаний можно использовать ту же функцию predict что и для бустинга на деревьях<br>\n",
    "<i>Примечания: в LogLoss необходимо передавать не предсказания полученные с помощью clf.predict(...), а вероятность, полученную с помощью clf.predict_proba(...)[:, 1] \n",
    "    \n",
    "   Реализовать специальную функцию predict для бустинга на логистической регрессии выводящую предсказания по формуле: $ Predictions=sign(Score_{bust}) $,\n",
    "где sign равен единице для положительных и нулю для отрицательных значений, а $ Score_{bust}= \\sum \\alpha_iScore_i$. Баллы выдаваемые каждой моделью $Score_i$ можно найти при помощи вызова метода decision_function на моделе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import model_selection\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "def get_error(pred, y):\n",
    "    return np.sum((pred != y).astype(int)) / len(y)\n",
    "\n",
    "def log_loss(pred, y):\n",
    "    return -np.sum(y*np.log(pred)+(1-y)*np.log(1-pred))/len(y)\n",
    "\n",
    "def predict_proba(X):\n",
    "    return 1/(1+np.exp(-1*X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaboost(X, y, N):\n",
    "\n",
    "    # Размер выборки\n",
    "    n_objects = len(X)\n",
    "\n",
    "    # Запишем количество классов в переменную\n",
    "    n_classes = len(np.unique((y)))\n",
    "\n",
    "    # Начальные веса деревьев\n",
    "    w = np.ones(n_objects) / n_objects\n",
    "\n",
    "    # Деревья с весами будем записывать в список\n",
    "    models = []\n",
    "\n",
    "    for n in range(N):\n",
    "        # Зададим дерево и обучим его\n",
    "        clf = DecisionTreeClassifier(max_depth=1)\n",
    "        clf.fit(X, y, sample_weight=w)\n",
    "\n",
    "        predictions = clf.predict(X)\n",
    "        e = get_error(predictions, y)\n",
    "        # отбросим дерево, если его ошибка больше 0.5\n",
    "        # Запишем условие в общем виде (применимо к небинарным классификаторам)\n",
    "        if e >= 1 - 1/n_classes: \n",
    "            break\n",
    "\n",
    "        # Вычислим вес для дерева\n",
    "        alpha = 0.5 * np.log((1 - e) / e)\n",
    "\n",
    "        # Найдем индексы правильно классифицированных элементов\n",
    "        match = predictions == y\n",
    "\n",
    "        # Увеличим веса для неправильно классифицированных элементов\n",
    "        w[~match] *= np.exp(alpha)\n",
    "\n",
    "        # Нормализуем веса\n",
    "        w /= w.sum()\n",
    "\n",
    "        # Добавим дерево с весом в список\n",
    "        models.append((alpha, clf))\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaboost_logloss(X, y, N):\n",
    "\n",
    "    # Размер выборки\n",
    "    n_objects = len(X)\n",
    "\n",
    "    # Запишем количество классов в переменную\n",
    "    n_classes = len(np.unique((y)))\n",
    "\n",
    "    # Начальные веса деревьев\n",
    "    w = np.ones(n_objects) / n_objects\n",
    "\n",
    "    # Деревья с весами будем записывать в список\n",
    "    models = []\n",
    "\n",
    "    for n in range(N):\n",
    "        # Зададим дерево и обучим его\n",
    "        clf = LogisticRegression()\n",
    "      \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            #и здесь обучаем модели\n",
    "            clf.fit(X, y, w)\n",
    "    \n",
    "            predictions = clf.predict_proba(X)[:, 1]\n",
    "            e = log_loss(predictions, y)\n",
    "            # отбросим дерево, если его ошибка больше 0.5\n",
    "            # Запишем условие в общем виде (применимо к небинарным классификаторам)\n",
    "            if e >= 1 - 1/n_classes: \n",
    "                break\n",
    "    \n",
    "            # Вычислим вес для дерева\n",
    "            alpha = 0.5 * np.log((1 - e) / e)\n",
    "    \n",
    "            # Найдем индексы правильно классифицированных элементов\n",
    "            match = (predictions > 0.5).astype(int) == y\n",
    "    \n",
    "            # Увеличим веса для неправильно классифицированных элементов\n",
    "            w[~match] *= np.exp(alpha)\n",
    "    \n",
    "            # Нормализуем веса\n",
    "            w /= w.sum()\n",
    "    \n",
    "            # Добавим дерево с весом в список\n",
    "            models.append((alpha, clf, predictions))\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучим 50 деревьев\n",
      "\n",
      "Создалось 17 моделей, с alpha равными \n",
      "\n",
      "0.9500241273522885\n",
      "0.6889659234876808\n",
      "0.6232658668730207\n",
      "0.4819300280617255\n",
      "0.35127226349851454\n",
      "0.2169607178430995\n",
      "0.14972052185645207\n",
      "0.10613078027397012\n",
      "0.08498903033363571\n",
      "0.059227622248973884\n",
      "0.028313372071370302\n",
      "0.013400963724539118\n",
      "0.007212993702055966\n",
      "0.0130045602146961\n",
      "0.015567202211203633\n",
      "0.007918816964903739\n",
      "0.02230522637292671\n"
     ]
    }
   ],
   "source": [
    "N = 50\n",
    "models = adaboost_logloss(X_train, y_train, N)\n",
    "print(f'Обучим {N} деревьев\\n\\nСоздалось {len(models)} моделей, с alpha равными \\n')\n",
    "for m in models:\n",
    "    print(m[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, models):\n",
    "    \n",
    "    n_classes = 2\n",
    "    n_objects = len(X)\n",
    "    \n",
    "    # вначале обозначим предсказание нулевым массивом\n",
    "    y_pred = np.zeros((n_objects, n_classes))\n",
    "    \n",
    "    for alpha, clf, pred in models:\n",
    "        prediction = clf.predict(X)\n",
    "        \n",
    "        # Для каждого предсказания будем прибавлять alpha к\n",
    "        # элементу с индексом предсказанного класса\n",
    "        y_pred[range(n_objects), prediction] += alpha\n",
    "        \n",
    "    # выберем индексы с максимальными суммарными весами -\n",
    "    # получим предсказанные алгоритмом классы\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_predict(X, models):\n",
    "    n_classes = 2\n",
    "    n_objects = len(X)\n",
    "    \n",
    "    y_pred = np.array(0)\n",
    "    \n",
    "    for alpha, clf, pred in models:\n",
    "        \n",
    "        # Получаем score умножением соответствующего alpha\n",
    "        # на соответсвующий вектор предсказаний\n",
    "        score = alpha * clf.decision_function(X)\n",
    "        \n",
    "        # Вычисляем суммарный вектор\n",
    "        y_pred = y_pred + score\n",
    "        \n",
    "    for num, s in enumerate(y_pred):\n",
    "        \n",
    "        # Если больше 0, то 1, если меньше - 0.\n",
    "        if s >= 0:\n",
    "            y_pred[num] = 1\n",
    "        else: \n",
    "            y_pred[num] = 0\n",
    "            \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность первого алгоритма на обучающей выборке: 93.427\n",
      "Точность второго алгоритма на обучающей выборке: 94.131\n",
      "Точность первого алгоритма на тестовой выборке с LogLoss: 51.168\n",
      "Точность второго алгоритма на тестовой выборке с LogLoss: 51.434\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    print(f'Точность первого алгоритма на обучающей выборке: {(1 - get_error(predict(X_train, models), y_train)) * 100:.3f}')\n",
    "    print(f'Точность второго алгоритма на обучающей выборке: {(1 - get_error(my_predict(X_train, models), y_train)) * 100:.3f}')\n",
    "    print(f'Точность первого алгоритма на тестовой выборке с LogLoss: {(1 - log_loss(predict_proba(predict(X_test, models)), y_test)) * 100:.3f}')\n",
    "    print(f'Точность второго алгоритма на тестовой выборке с LogLoss: {(1 - log_loss(predict_proba(my_predict(X_test, models)), y_test)) * 100:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему такая точность у LogLoss не понятно..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
